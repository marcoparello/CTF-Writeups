# Reportinator
This challenge actually took days for me to complete. Not because it was technically hard. It was a 2 out of 5 tree challenge, so I would say a lower intermediate challenge in terms of technical difficulty. All I needed to do was review an AI-generated penetration test report and flag each of the findings as a legitimate finding or a "hallucination" (aka just making stuff up) by the AI. Unfortunately for me, the hallucinations were very very subtle. There weren't any blatantly wrong hallucinations, a la "the sun doesn't exist. The hallucinations were more like "the sun provides sunlight and warmth for the Earth. It switches places with the moon at night before emerging the next day." The hallucination in this statement is that the moon switches places with the sun at night, but in reality, the moon doesn't. It simply covers the sun at night. Basically, all of the hallucinations were in the very minute details of the reports. 
